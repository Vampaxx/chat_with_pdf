{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Asus\\\\vs_code\\\\chat_with_pdf\\\\notebook'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import streamlit as st \n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import GooglePalm\n",
    "from src.chat_with_pdf.utils.common import *\n",
    "from langchain.prompts import SemanticSimilarityExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = \"\"\"ARJUN P V\n",
    "Data Scientist / Machine Learning\n",
    "(+91) 9400508669\n",
    "arjunappu1001@gmail.com\n",
    "https://github.com/Vampaxx\n",
    "Linkedin link\n",
    "OVERVIEW Working professional with around 3 years of industrial experience and 1.8 years of relevant\n",
    "experience in Data science and Machine learning field. I have a strong foundation in Machine\n",
    "learning, Data analysis and deep learning working on various projects, gaining a diverse set of\n",
    "skills. I'm a valuable contributor to any team and well-equipped to handle the challenges and\n",
    "responsibilities of being a passionate Data scientist. Dedicated to leveraging my analytical skills\n",
    "and keen eye for data trends, patterns to empower organizations in making data driven decisions.\n",
    "EDUCATION APJ ABDUL KALAM TECHNOLOGICAL UNIVERSITY 2015-2019\n",
    "• Bachelors in Mechanical Engineering\n",
    "WORKING EXPERIENCE\n",
    "• Data Scientist | Strategist [10/2022 - Present]\n",
    "Indo Space Cable Network\n",
    "o Successfully orchestrated a remarkable 41% surge in internet connections over the 4 months,\n",
    "driving substantial business growth and expanding the company's market presence.\n",
    "o Better allocation of service team to improve the service quality and save time and improve profit of\n",
    "the company.\n",
    "o “Proposed Project: “Complaint registration and auto allocation of Service man”\n",
    "• Data Scientist | Machine Learning Engineer [04/2022 - Present]\n",
    "Freelancing\n",
    "o Successfully developed a highly accurate brain tumor prediction model using MRI images,\n",
    "achieving an impressive 95% accuracy [TensorFlow, CNN, git, Pipeline building, API, Python,\n",
    "Keras]\n",
    "• Managing data and workflows in a more organized and reproducible manner by DvC\n",
    "o Developed Diabetic retinopathy multiclass prediction model, with 42% improvement with CNN\n",
    "ensemble model by model optimization and image preprocessing and hyperparameter tuning.\n",
    "• Combine different CNN architecture to improve the performance of models (+8%)\n",
    "o Analysis data and generate insight to business for better understand the customer demand and\n",
    "improved the inventory control. [Python, Statistical analysis ] [02/2022]\n",
    "• Mechanical Engineering Trainee [05/2021 - 05/2022]\n",
    "The Western India Plywoods LTD.\n",
    "o Preventive and breakdown maintenance of plant, comprising of hydraulic presses, Boiler, Air\n",
    "compressor, Defibrator, Pumps, Control Valves etc\n",
    "o Preventive and breakdown maintenance of resin plant, hydraulic and pneumatic machines.\n",
    "o Quality control & Quality assurance\n",
    "TECHNICAL SKILLS\n",
    "• Programming Languages:\n",
    "o Python: Proficient data manipulation, analysis, and building machine learning models,\n",
    "OOPs concept\n",
    "o SQL\n",
    "• Machine Learning:\n",
    "o Deep Learning: CNN, Neural network, NLP, LSTM, LLM (Large Language Model)\n",
    "o Supervised learning: Linear Regression, KNN\n",
    "o Hyperparameter Tuning: Expertise in fine-tuning model parameters\n",
    "• Numpy, Pandas, Scikit Learn, TensorFlow, Keras, Matplotlib, Seaborn\n",
    "• Data Analysis data Processing, data cleaning, Image preprocessing,Data Visualization\n",
    "• Mathematics and Statistics:\n",
    "▪ Feature extraction,\n",
    "• Crafting Data Pipelines, Data Ingestion, Model Building\n",
    "• Git,WebAPI, Pyspark\n",
    "SOFT SKILLS\n",
    "• Creative, Analytical and problem-solving skills\n",
    "• Strong team mentality\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    load_dotenv()\n",
    "    model   = GooglePalm(google_api_key=os.getenv(\"PALM_API_KEY\"),temperature=0.1)\n",
    "    memory = ConversationBufferMemory(llm=model,  \n",
    "                                        output_key='answer',\n",
    "                                        memory_key='chat_history',\n",
    "                                        return_messages=True)\n",
    "\n",
    "    text_chunks = get_text_chunks(pdf_text)\n",
    "    vector      = get_vectorstore(text_chunks=text_chunks)\n",
    "    conversation= ConversationalRetrievalChain.from_llm(llm=model,   \n",
    "                                                memory=memory,\n",
    "                                                retriever = vector.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 2, \"include_metadata\": True}),\n",
    "                                                chain_type='stuff',\n",
    "                                                return_source_documents=True,\n",
    "                                                get_chat_history=lambda h : h,\n",
    "                                                verbose=False)\n",
    "    \n",
    "    return conversation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='company name'), AIMessage(content='Indo Space Cable Network')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = conversation({\"question\": \"company name\"})\n",
    "print(f\"{response['chat_history']}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='company name'), AIMessage(content='Indo Space Cable Network'), HumanMessage(content='which project he done in this company'), AIMessage(content='Proposed Project: “Complaint registration and auto allocation of Service man”')]\n",
      "\n",
      "[HumanMessage(content='company name'), AIMessage(content='Indo Space Cable Network'), HumanMessage(content='which project he done in this company'), AIMessage(content='Proposed Project: “Complaint registration and auto allocation of Service man”'), HumanMessage(content='in which company he does the project , the project name is brain tumor prediction model'), AIMessage(content='Freelancing')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = conversation({\"question\": \"which project he done in this company\"})\n",
    "print(f\"{response['chat_history']}\\n\")\n",
    "\n",
    "response = conversation({\"question\": \"in which company he does the project , the project name is brain tumor prediction model\"})\n",
    "print(f\"{response['chat_history']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company name\n",
      "company name\n",
      "which project he done in this company\n",
      "which project he done in this company\n",
      "in which company he does the project , the project name is brain tumor prediction model\n",
      "in which company he does the project , the project name is brain tumor prediction model\n"
     ]
    }
   ],
   "source": [
    "for i,message in enumerate(response['chat_history']):\n",
    "    if i%2 == 0:\n",
    "        user = message\n",
    "    else:\n",
    "        jarvis = message\n",
    "    print(user.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model   = GooglePalm(google_api_key=os.getenv(\"PALM_API_KEY\"),temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = vector.as_retriever(search_type='similarity',search_kwargs={\"k\":2})\n",
    "memory  = ConversationBufferMemory(memory_key='chat_history',return_message=True)\n",
    "chat_model = ConversationalRetrievalChain.from_llm(\n",
    "                        llm=model,\n",
    "                        retriever=database,\n",
    "                        memory = memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "quary = \"what is the total number of AI publication \"\n",
    "response  = chat_model({'question':quary,'chat_history':chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(quary,response['answer'])]\n",
    "quary       = \"what is the anser when number 25/5\"\n",
    "response    = chat_model({'question':quary,'chat_history':chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what is the total number of AI publication ', '0')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [(quary,response['answer'])]\n",
    "quary       = \"anser multiply by 100\"\n",
    "response    = chat_model({'question':quary,'chat_history':chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'500'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what is the anser when number 25/5', '5')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
